predictors <- names(ensembleData)[names(ensembleData) != c(labelName)] # Modify acordingly to capture irrelevant features such as product id
predictors
testing_horizon
createTimeSlices(ensembleData, initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
# Define  training control, one for caret, another for non-caret usage for individual model training
number_of_splits <- 7 #MODİFY -> number of train,test pairs
createTimeSlices(ensembleData, initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
ensembleData
createTimeSlices(nrow(ensembleData), initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
idx <- createTimeSlices(1:train_size, initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
idx
controller <- trainControl(method = "timeslice",
initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
myControl
myControl <- trainControl(method = "timeslice",
initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
blend_size/2
floor(blend_size/2)
# Additional controller to ensemble the models
controller <- trainControl(method = "timeslice",
initialWindow = floor(blend_size/2),
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(blenderData[,predictors], blenderData[,labelName], method='gbm', trControl=myControl)
blenderData[,predictors]
blenderData[,labelName]
blenderData
test_model <- train("sales ~ .",blenderData, method='gbm', trControl=myControl)
test_model <- train("sales ~.",blenderData, method='gbm', trControl=myControl)
require(gbm)
test_model <- train("sales ~.",blenderData, method='gbm', trControl=myControl)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=myControl)
blenderData
sales
blenderData
blenderData$sales
fit <- train(sales ~ .,
data = blenderData,
method = "gbm",
trControl = myControl
)
# FOR LOOP entry point, for simplicity I focused on single product
# However, since following code will depend on id, this can be easilty enveloped in a foor loop
id <- ydata$product_id[700]
df_prod <- df[df$product_id == id,] ## product y data
data_size <- nrow(df_prod)
# Partition data for training, blending and testing purposes
# Assuming that all data is of same size
train_size <- 140 #MODIFY
blend_size <- 30  #MODIFY
test <- 30        #MODIFY
train_size + blend_size + test == data_size #Ensure using all data
#Set to preferred value
testing_horizon <- 7 #MODIFY
# Some preprocessing, since they are not handled in initial preprocessing step
df_prod <- df_prod[,names(ensembleData)[names(ensembleData) != "product_id"]] #drop product_id
# Use to remove linear dependence
comboInfo <- findLinearCombos(df_prod)
df_prod <- df_prod[, -comboInfo$remove]
# Remove highly correlated features
# This part can be removed, if a feature selection algorithm is provided
# However since I dont implement such a thing act acordingly
#MODIFY
descrCor <-  cor(df_prod)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
df_prod <- df_prod[,-highlyCorDescr]
# Parition data
ensembleData <- df_prod[1:train_size,] # Will be used to train individual models
blenderData <- df_prod[(train_size+1):(train_size+blend_size),] # Will be used to train ensembling model
testingData <- df_prod[(train_size+blend_size+1):data_size,] # Will be used to test overall model performance
labelName <- "sales" # Name of the predictor variable
# Modify acordingly to capture irrelevant features such as product id
predictors <- names(ensembleData)[names(ensembleData) != c(labelName)] #MODIFY
# Define  training control, one for caret, another for non-caret usage for individual model training
number_of_splits <- 7 #MODİFY -> number of train,test pairs
myControl <- trainControl(method = "timeslice",
initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
idx <- createTimeSlices(1:train_size, initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
trainSlices <- idx[[1]]
testSlices <- idx[[2]]
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = floor(blend_size/2),
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=myControl)
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = floor(blend_size/2),
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=myControl)
train_size
number_of_splits*testing_horizon
testing_horizon
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=controller)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=controller)
warnings()
floor(blend_size*8/10)
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = floor(blend_size*8/10),
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=controller)
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = blend_size - 5,
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=controller)
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = blend_size - 1,
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=controller)
# Partition data for training, blending and testing purposes
# Assuming that all data is of same size
train_size <- 120 #MODIFY
blend_size <- 50  #MODIFY
test <- 30        #MODIFY
train_size + blend_size + test == data_size #Ensure using all data
#Set to preferred value
testing_horizon <- 7 #MODIFY
# Some preprocessing, since they are not handled in initial preprocessing step
df_prod <- df_prod[,names(ensembleData)[names(ensembleData) != "product_id"]] #drop product_id
# Use to remove linear dependence
comboInfo <- findLinearCombos(df_prod)
df_prod <- df_prod[, -comboInfo$remove]
# Remove highly correlated features
# This part can be removed, if a feature selection algorithm is provided
# However since I dont implement such a thing act acordingly
#MODIFY
descrCor <-  cor(df_prod)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
df_prod <- df_prod[,-highlyCorDescr]
# Parition data
ensembleData <- df_prod[1:train_size,] # Will be used to train individual models
blenderData <- df_prod[(train_size+1):(train_size+blend_size),] # Will be used to train ensembling model
testingData <- df_prod[(train_size+blend_size+1):data_size,] # Will be used to test overall model performance
labelName <- "sales" # Name of the predictor variable
# Modify acordingly to capture irrelevant features such as product id
predictors <- names(ensembleData)[names(ensembleData) != c(labelName)] #MODIFY
# Define  training control, one for caret, another for non-caret usage for individual model training
number_of_splits <- 7 #MODİFY -> number of train,test pairs
myControl <- trainControl(method = "timeslice",
initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
idx <- createTimeSlices(1:train_size, initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
trainSlices <- idx[[1]]
testSlices <- idx[[2]]
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = blend_size - 1,
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=controller)
test_model <- train(sales ~.,data = blenderData, method='gbm', trControl=controller)
test_model <- train(sales ~ .,data = blenderData, method='gbm', trControl=controller)
blenderData
ydata <- read_csv(y_path)
xdata<- read_csv(x_path)
df <- data.frame(cbind(ydata, xdata))
# FOR LOOP entry point, for simplicity I focused on single product
# However, since following code will depend on id, this can be easilty enveloped in a foor loop
id <- ydata$product_id[700]
df_prod <- df[df$product_id == id,] ## product y data
data_size <- nrow(df_prod)
# Partition data for training, blending and testing purposes
# Assuming that all data is of same size
train_size <- 120 #MODIFY
blend_size <- 50  #MODIFY
test <- 30        #MODIFY
train_size + blend_size + test == data_size #Ensure using all data
#Set to preferred value
testing_horizon <- 7 #MODIFY
# Some preprocessing, since they are not handled in initial preprocessing step
df_prod <- df_prod[,names(ensembleData)[names(ensembleData) != "product_id"]] #drop product_id
# Use to remove linear dependence
comboInfo <- findLinearCombos(df_prod)
df_prod <- df_prod[, -comboInfo$remove]
# Remove highly correlated features
# This part can be removed, if a feature selection algorithm is provided
# However since I dont implement such a thing act acordingly
#MODIFY
descrCor <-  cor(df_prod)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
df_prod <- df_prod[,-highlyCorDescr]
# Parition data
ensembleData <- df_prod[1:train_size,] # Will be used to train individual models
blenderData <- df_prod[(train_size+1):(train_size+blend_size),] # Will be used to train ensembling model
testingData <- df_prod[(train_size+blend_size+1):data_size,] # Will be used to test overall model performance
testingData
# Read data here
# Change data path for x and y acordingly
x_path <- "dataX.csv" #MODIFY
y_path <- "dataY.csv" #MODIFY
ydata <- read_csv(y_path)
xdata<- read_csv(x_path)
df <- data.frame(cbind(ydata, xdata))
df
# FOR LOOP entry point, for simplicity I focused on single product
# However, since following code will depend on id, this can be easilty enveloped in a foor loop
id <- ydata$product_id[400]
df_prod <- df[df$product_id == id,] ## product y data
data_size <- nrow(df_prod)
# Partition data for training, blending and testing purposes
# Assuming that all data is of same size
train_size <- 120 #MODIFY
blend_size <- 50  #MODIFY
test <- 30        #MODIFY
train_size + blend_size + test == data_size #Ensure using all data
#Set to preferred value
testing_horizon <- 7 #MODIFY
# Some preprocessing, since they are not handled in initial preprocessing step
df_prod <- df_prod[,names(ensembleData)[names(ensembleData) != "product_id"]] #drop product_id
# Use to remove linear dependence
comboInfo <- findLinearCombos(df_prod)
df_prod <- df_prod[, -comboInfo$remove]
# Remove highly correlated features
# This part can be removed, if a feature selection algorithm is provided
# However since I dont implement such a thing act acordingly
#MODIFY
descrCor <-  cor(df_prod)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
df_prod <- df_prod[,-highlyCorDescr]
# Parition data
ensembleData <- df_prod[1:train_size,] # Will be used to train individual models
blenderData <- df_prod[(train_size+1):(train_size+blend_size),] # Will be used to train ensembling model
testingData <- df_prod[(train_size+blend_size+1):data_size,] # Will be used to test overall model performance
labelName <- "sales" # Name of the predictor variable
# Modify acordingly to capture irrelevant features such as product id
predictors <- names(ensembleData)[names(ensembleData) != c(labelName)] #MODIFY
# Define  training control, one for caret, another for non-caret usage for individual model training
number_of_splits <- 7 #MODİFY -> number of train,test pairs
myControl <- trainControl(method = "timeslice",
initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
idx <- createTimeSlices(1:train_size, initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
trainSlices <- idx[[1]]
testSlices <- idx[[2]]
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = blend_size - 1,
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~ .,data = blenderData, method='gbm', trControl=controller)
#This defines an ensamble model defined by method_list, and combined using ensembler_method
#List of methods avaliavle in caret to ensemble
method_list <- c() #MODIFY
blenderData
df_prod
ydata <- read_csv(y_path)
xdata<- read_csv(x_path)
df <- data.frame(cbind(ydata, xdata))
df
# FOR LOOP entry point, for simplicity I focused on single product
# However, since following code will depend on id, this can be easilty enveloped in a foor loop
id <- ydata$product_id[300]
df_prod <- df[df$product_id == id,] ## product y data
df_prod
data_size <- nrow(df_prod)
# Partition data for training, blending and testing purposes
# Assuming that all data is of same size
train_size <- 120 #MODIFY
blend_size <- 50  #MODIFY
test <- 30        #MODIFY
train_size + blend_size + test == data_size #Ensure using all data
#Set to preferred value
testing_horizon <- 7 #MODIFY
# Some preprocessing, since they are not handled in initial preprocessing step
df_prod <- df_prod[,names(ensembleData)[names(ensembleData) != "product_id"]] #drop product_id
df_prod
df_prod
df_prod <- df[df$product_id == id,] ## product y data
data_size <- nrow(df_prod)
# Partition data for training, blending and testing purposes
# Assuming that all data is of same size
train_size <- 120 #MODIFY
blend_size <- 50  #MODIFY
test <- 30        #MODIFY
train_size + blend_size + test == data_size #Ensure using all data
df_prod
names(ensembleData)[names(ensembleData) != "product_id"]
# Some preprocessing, since they are not handled in initial preprocessing step
df_prod <- df_prod[,names(df_prod)[names(df_prod) != "product_id"]] #drop product_id
df_prod
# Use to remove linear dependence
comboInfo <- findLinearCombos(df_prod)
comboInfo
df_prod <- df_prod[, -comboInfo$remove]
df_prod
# Remove highly correlated features
# This part can be removed, if a feature selection algorithm is provided
# However since I dont implement such a thing act acordingly
#MODIFY
descrCor <-  cor(df_prod)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
highlyCorDescr
df_prod <- df_prod[,-highlyCorDescr]
# Parition data
ensembleData <- df_prod[1:train_size,] # Will be used to train individual models
blenderData <- df_prod[(train_size+1):(train_size+blend_size),] # Will be used to train ensembling model
testingData <- df_prod[(train_size+blend_size+1):data_size,] # Will be used to test overall model performance
labelName <- "sales" # Name of the predictor variable
# Modify acordingly to capture irrelevant features such as product id
predictors <- names(ensembleData)[names(ensembleData) != c(labelName)] #MODIFY
# Define  training control, one for caret, another for non-caret usage for individual model training
number_of_splits <- 7 #MODİFY -> number of train,test pairs
myControl <- trainControl(method = "timeslice",
initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
idx <- createTimeSlices(1:train_size, initialWindow = train_size - number_of_splits*testing_horizon,
horizon = testing_horizon,
skip = testing_horizon -1,
fixedWindow = FALSE)
trainSlices <- idx[[1]]
testSlices <- idx[[2]]
# Additional controller to ensemble the models
#MODIFY acordingly
controller <- trainControl(method = "timeslice",
initialWindow = blend_size - 1,
horizon = 1,
skip = 0,
fixedWindow = FALSE)
test_model <- train(sales ~ .,data = blenderData, method='gbm', trControl=controller)
warnings()
test_model
preds <- predict(object=test_model, testingData[,predictors])
library(pROC)
auc <- roc(testingData[,labelName], preds)
err <- measures(as.matrix(testingData$sales), test_model, as.matrix(testingData$sales), benchmark = "naive")
library(forecast)
err <- measures(as.matrix(testingData$sales), test_model, as.matrix(testingData$sales), benchmark = "naive")
library(e1071)
library("dplyr")
library(readr)
library("dplyr")
library(glmnet)
library(factoextra)
??factoextra
install.packages("factoextra")
library(factoextra)
library(cluster)
library(tsintermittent)
err <- measures(as.matrix(testingData$sales), test_model, as.matrix(testingData$sales), benchmark = "naive")
??measures
#err <- measures(as.matrix(testingData$sales), test_model, as.matrix(testingData$sales), benchmark = "naive")
pred
preds <- predict(object=test_model, testingData[,predictors])
#err <- measures(as.matrix(testingData$sales), test_model, as.matrix(testingData$sales), benchmark = "naive")
pred
#err <- measures(as.matrix(testingData$sales), test_model, as.matrix(testingData$sales), benchmark = "naive")
preds
library(randomForest)
library(rpart)
for(model in model_list){
model_fit <- train(ensembleData[,predictors], ensembleData[,labelName], method='', trControl=myControl)
}
#This defines an ensamble model defined by method_list, and combined using ensembler_method
#List of methods avaliavle in caret to ensemble
method_list <- c("gbm", "rpart", "rf") #MODIFY
#Ensembling method, trained on blend data
ensembling_method <- "rf" #MODIFY
for(model in model_list){
model_fit <- train(ensembleData[,predictors], ensembleData[,labelName], method='', trControl=myControl)
}
#This defines an ensamble model defined by method_list, and combined using ensembler_method
#List of methods avaliavle in caret to ensemble
model_list <- c("gbm", "rpart", "rf") #MODIFY
#Ensembling method, trained on blend data
ensembling_method <- "rf" #MODIFY
for(model in model_list){
model_fit <- train(ensembleData[,predictors], ensembleData[,labelName], method='', trControl=myControl)
}
model
model_fit <- train(ensembleData[,predictors], ensembleData[,labelName], method=model, trControl=myControl)
predict(object=model_fit, blenderData[,predictors])
predict(object=model_fit, testingData[,predictors])
blenderData$"sales"
for(model in model_list){
model_fit <- train(ensembleData[,predictors], ensembleData[,labelName], method=model, trControl=myControl)
blenderData$model <- predict(object=model_fit, blenderData[,predictors])
testingData$model <- predict(object=model_fit, testingData[,predictors])
}
model_fit
blenderData
blenderData[model] <- predict(object=model_fit, blenderData[,predictors])
for(model in model_list){
model_fit <- train(ensembleData[,predictors], ensembleData[,labelName], method=model, trControl=myControl)
blenderData[model] <- predict(object=model_fit, blenderData[,predictors])
testingData[model] <- predict(object=model_fit, testingData[,predictors])
}
blenderData
names(blenderData)
[names(blenderData) != labelName]
names(blenderData)[names(blenderData) != labelName]
model_list
predictors <- model_list
blenderData[,labelName]
blenderData[,predictors]
predictors <- model_list
final_blender_model <- train(blenderData[,predictors], blenderData[,labelName], method=ensembling_method, trControl=controller)
final_blender_model
preds <- predict(object=final_blender_model, testingData[,predictors])
preds
# Mase function if necessary
# Mase function
computeMASE <- function(forecast,train,test,period){
# forecast - forecasted values
# train - data used for forecasting .. used to find scaling factor
# test - actual data used for finding MASE.. same length as forecast
# period - in case of seasonal data.. if not, use 1
forecast <- as.vector(forecast)
train <- as.vector(train)
test <- as.vector(test)
n <- length(train)
scalingFactor <- sum(abs(train[(period+1):n] - train[1:(n-period)])) / (n-period)
et <- abs(test-forecast)
qt <- et/scalingFactor
meanMASE <- mean(qt)
return(meanMASE)
}
computeMASE(preds,rbind(ensembleData$sales,blenderData$sales),testingData$sales,test)
ensembleData$sales
rbind(ensembleData$sales,blenderData$sales)
c(ensembleData$sales,blenderData$sales)
computeMASE(preds,c(ensembleData$sales,blenderData$sales),testingData$sales,test)
computeMASE(preds,c(ensembleData$sales,blenderData$sales),testingData$sales,test)
preds
c(ensembleData$sales,blenderData$sales)
training_sales_data <- c(ensembleData$sales,blenderData$sales)
computeMASE(preds,ensembleData$sales,testingData$sales,test)
computeMASE(preds,blenderData$sales,testingData$sales,test)
computeMASE(preds,training_sales_data,testingData$sales,test)
predictors <- model_list
#Libraries
library(readr)#To read data from csv
# Training libraries
library(RSNNS)
library(forecast)#Common forecasting functionality
library(caret) #Uniform modelling interface
library(kernlab)
library(gbm)
library(e1071)
library("dplyr")
library(glmnet) #For elastic net -> regularization algorithm
library(randomForest)
library(rpart)
library(tsintermittent)
library("greybox")
# Miscellenaus
library(ggplot2)
#Set seed for reproducibility
set.seed(1)
inputy <- c("featureCreation/new50Y.csv")
inputy2 <- paste(inputy, collapse="")
inputx <- c("featureCreation/new50.csv")
inputx2 <- paste(inputx, collapse="")
inputElastic<-c("featureSelection/newElastic50.csv")
